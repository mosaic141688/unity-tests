"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const immutable_1 = require("immutable");
const ramda_1 = require("ramda");
exports.BASIC_TYPES = ['number', 'string', 'bool'];
exports.CONTAINER_TYPES = ['record', 'list'];
exports.ALL_TYPES = exports.BASIC_TYPES.concat(exports.CONTAINER_TYPES);
/*
 * Useful for resolving generics in the output of transform
 * Given input of type A for filter with input B and output C
 * We can call:
 *
 * applyGenerics(A, B, C) -> D
 *
 * D will be the typestring result of applying generics found
 * after matchTypes(A, B) onto C
 *
 * TODO: Implement this and use in pipeline
 */
function applyGenerics(value_type, input_type, output_type) {
    const [match, generics] = matchTypes(value_type, input_type);
    if (match) {
        return {
            input_type: match,
            output_type: toTypeString(applyGenericsToTypeMap(fromTypeString(output_type), generics))
        };
    }
    else {
        throw Error(`Value type ${value_type} does not match input type ${input_type}`);
    }
}
exports.applyGenerics = applyGenerics;
function applyGenericsToTypeMap(typemap, generics) {
    return typemap.mapEntries(([entry_name, entry_content]) => {
        const same_name_generic = generics.find((content, name) => {
            return name === entry_name;
        });
        const same_content_generic = generics.findEntry((content, name) => {
            return (entry_content !== true && entry_name !== 'record' && name === entry_content.keySeq().first());
        });
        const same_content_record_generic = generics.findEntry((content, name) => {
            return (entry_content !== true && entry_name === 'record' && name === entry_content.keySeq().first());
        });
        if (same_content_generic !== undefined) {
            return [entry_name, same_content_generic[1]];
        }
        if (same_content_record_generic !== undefined) {
            const new_content = entry_content.delete(same_content_record_generic[0]);
            return [entry_name, new_content.merge(same_content_record_generic[1])];
        }
        if (same_name_generic !== undefined) {
            const [new_name, new_content] = getNameContent(same_name_generic);
            return [new_name, new_content];
        }
        if (exports.CONTAINER_TYPES.includes(entry_name)) {
            const new_content = applyGenericsToTypeMap(entry_content, generics);
            return [entry_name, new_content];
        }
        return [entry_name, entry_content];
    });
}
/*
 * Resolve two types into one if possible
 */
function resolveTypes(ts_a, ts_b) {
    const [typestring, result_generics] = matchTypes(ts_a, ts_b);
    return typestring;
}
exports.resolveTypes = resolveTypes;
/*
 * Match two type strings and determine if they are compatible
 * If strings contained generics try to resolve them
 * Returns resolved type or null of types don't match
 *
 * Example:
 *
 * number number -> number
 * [number] [a] -> [number]
 */
function matchTypes(ts_a, ts_b) {
    // if two types are identical we return right away
    if (ts_a === ts_b)
        return [ts_a, immutable_1.Map()];
    // if two type strings are different, we try to resolve generics
    const tm_a = fromTypeString(ts_a);
    const tm_b = fromTypeString(ts_b);
    // if two typemaps are identical we return typestring for first
    // this can matter if record fields are out of order but still identical
    if (tm_a.equals(tm_b))
        return [ts_a, immutable_1.Map()];
    const [name_a, content_a] = getNameContent(tm_a);
    const [name_b, content_b] = getNameContent(tm_b);
    const [result_typemap, result_generics] = resolveGenerics([immutable_1.Map(), immutable_1.Map()], name_a, content_a, name_b, content_b);
    if (result_typemap) {
        return [toTypeString(result_typemap), result_generics];
    }
    else {
        return [null, result_generics];
    }
}
/*
 * Try to construct a new typemap by resolving all generics between two types
 */
function resolveGenerics(result, name_a, content_a, name_b, content_b) {
    let [result_typemap, result_generics] = result;
    // if both values are of basic type try to resolve one generic
    if (content_a === true && content_b === true) {
        // when A is generic and B is not
        if (exports.BASIC_TYPES.includes(name_b) && !exports.BASIC_TYPES.includes(name_a)) {
            let resolved_content;
            if (content_a === true) {
                resolved_content = result_typemap.set(name_b, content_a);
            }
            else {
                resolved_content = result_typemap.set(name_b, content_b);
            }
            if (result_generics.get(name_a) === undefined || resolved_content.equals(result_generics.get(name_a))) {
                return [resolved_content, result_generics.set(name_a, resolved_content)];
            }
            else {
                return [null, result_generics.set(name_a, resolved_content)];
            }
        }
        // when B is generic and A is not
        if (exports.BASIC_TYPES.includes(name_a) && !exports.BASIC_TYPES.includes(name_b)) {
            let resolved_content;
            if (content_a === true) {
                resolved_content = result_typemap.set(name_a, content_b);
            }
            else {
                resolved_content = result_typemap.set(name_a, content_a);
            }
            if (result_generics.get(name_b) === undefined || resolved_content.equals(result_generics.get(name_b))) {
                return [resolved_content, result_generics.set(name_b, resolved_content)];
            }
            else {
                return [null, result_generics.set(name_b, resolved_content)];
            }
        }
    }
    // if both values are lists we go down recursively
    if (name_a === 'list' && name_b === 'list') {
        const [inner_name_a, inner_content_a] = getNameContent(content_a);
        const [inner_name_b, inner_content_b] = getNameContent(content_b);
        const [inner_result_typemap, inner_result_generics] = resolveGenerics([immutable_1.Map(), result_generics], inner_name_a, inner_content_a, inner_name_b, inner_content_b);
        if (inner_result_typemap) {
            return [result_typemap.set('list', inner_result_typemap), inner_result_generics];
        }
        else {
            return [null, inner_result_generics];
        }
    }
    // if both values are records
    if (name_a === 'record' && typeof content_a !== 'boolean' && name_b === 'record' && typeof content_b !== 'boolean') {
        // find all equal fields
        const equal_fields = content_a.filter((content, name) => {
            const corresponding_field = content_b.get(name);
            return corresponding_field && corresponding_field.equals(content);
        });
        // find all fields unique to A
        const unique_fields_a = content_a.filter((content, name) => {
            const corresponding_field = content_b.get(name);
            return !corresponding_field || !corresponding_field.equals(content);
        });
        // find all fields with unique to B
        const unique_fields_b = content_b.filter((content, name) => {
            const corresponding_field = content_a.get(name);
            return !corresponding_field || !corresponding_field.equals(content);
        });
        // find all fields between uniques that don't share the key
        const unique_key_fields_a = unique_fields_a.filter((content, name) => {
            return !!!unique_fields_b.get(name);
        });
        const unique_key_fields_b = unique_fields_b.filter((content, name) => {
            return !!!unique_fields_a.get(name);
        });
        const unique_key_fields_all = unique_key_fields_a.merge(unique_key_fields_b);
        // check if we have generics in unique key fields
        const record_generic_fields = unique_key_fields_all.filter((content, name) => {
            return !exports.BASIC_TYPES.includes(name) && immutable_1.Map({}).equals(content);
        });
        if (unique_key_fields_all.count() > 0 && !(record_generic_fields.count() > 0)) {
            return [null, result_generics];
        }
        const unique_key_fields_without_generics = unique_key_fields_all.filter((content, name) => {
            return !immutable_1.Map({}).equals(content);
        });
        // Remember all generic fields for all field generics in both typemaps
        result_generics = record_generic_fields.reduce((acc, content, name) => {
            const current = acc.get(name, immutable_1.Map({ record: {} }));
            // TODO: Implement
            return acc.set(name, unique_key_fields_without_generics);
        }, result_generics);
        // find all fields between uniques that has the same key
        const same_key_fields_list = unique_fields_a.filter((content, name) => {
            return !!unique_fields_b.get(name);
        }).keySeq().toArray();
        // try to recursively resolve all generics for all different fields that share key
        const same_key_result_typemap = ramda_1.reduce((acc, field) => {
            const [field_typemap, field_generics] = acc;
            const [inner_name_a, inner_content_a] = getNameContent(unique_fields_a.get(field));
            const [inner_name_b, inner_content_b] = getNameContent(unique_fields_b.get(field));
            const [inner_result_typemap, inner_result_generics] = resolveGenerics([immutable_1.Map(), field_generics], inner_name_a, inner_content_a, inner_name_b, inner_content_b);
            if (field_typemap && inner_result_typemap) {
                return [field_typemap.set(field, inner_result_typemap), inner_result_generics];
            }
            else {
                return [null, inner_result_generics];
            }
        }, [immutable_1.Map(), result_generics], same_key_fields_list);
        const [record_same_content_typemap, record_same_content_generics] = same_key_result_typemap;
        if (record_same_content_typemap) {
            return [immutable_1.Map({ record: equal_fields.merge(record_same_content_typemap).merge(unique_key_fields_without_generics) }), record_same_content_generics];
        }
    }
    return [null, result_generics];
}
function getNameContent(typemap) {
    return [typemap.keySeq().first() || '', typemap.valueSeq().first() || false];
}
function isGenericType(typemap) {
    return typemap.count() === 1 && typemap.first() === true && !exports.ALL_TYPES.includes(typemap.keySeq().first());
}
exports.isGenericType = isGenericType;
function isBasicType(typemap) {
    return typemap.count() === 1 && exports.BASIC_TYPES.includes(typemap.keySeq().first());
}
exports.isBasicType = isBasicType;
/*
 * Create type string from typemap
 */
function toTypeString(typemap) {
    if (isBasicType(typemap) || isGenericType(typemap)) {
        return typemap.keySeq().first();
    }
    if (typemap.count() === 1 && typemap.keySeq().first() === 'list') {
        return `[${toTypeString(typemap.first())}]`;
    }
    if (typemap.count() === 1 && typemap.keySeq().first() === 'record') {
        return `{${toTypeString(typemap.first())}}`;
    }
    if (typemap.count() === 1 && typemap.keySeq().first() === 'computed') {
        return `*${toTypeString(typemap.first())}`;
    }
    return typemap.reduce((acc, value, key) => {
        if (value.equals(immutable_1.Map())) {
            return key;
        }
        else {
            if (acc === '') {
                return `${key}: ${toTypeString(value)}`;
            }
            else {
                return acc + `, ${key}: ${toTypeString(value)}`;
            }
        }
    }, '');
}
exports.toTypeString = toTypeString;
/*
 * Create type map from type string
 */
function fromTypeString(type) {
    let ParserMode;
    (function (ParserMode) {
        ParserMode[ParserMode["Basic"] = 0] = "Basic";
        ParserMode[ParserMode["Record"] = 1] = "Record";
        ParserMode[ParserMode["RecordKey"] = 2] = "RecordKey";
        ParserMode[ParserMode["RecordType"] = 3] = "RecordType";
        ParserMode[ParserMode["Computed"] = 4] = "Computed";
    })(ParserMode || (ParserMode = {}));
    // Tokenize type string
    const lexer = ramda_1.reduce((acc, c) => {
        if (c.match(/[a-z_]/i)) {
            acc.current += c;
        }
        else if (['[', ']', '{', '}', ':', ',', '*'].includes(c)) {
            acc.current !== '' && acc.tokens.push(acc.current);
            acc.tokens.push(c);
            acc.current = '';
        }
        return acc;
    }, { tokens: [], current: '' }, type.split(''));
    const tokens = lexer.tokens.concat(lexer.current === '' ? [] : lexer.current);
    // Parse tokens
    const parser = ramda_1.reduce((acc, token) => {
        if (token.match(/[a-z_]+/i)) {
            switch (acc.mode) {
                case ParserMode.Basic:
                    acc.path.push(token);
                    acc.tree = acc.tree.setIn(acc.path, true);
                    break;
                case ParserMode.RecordKey:
                    acc.path.push(token);
                    acc.tree = acc.tree.setIn(acc.path, immutable_1.Map({}));
                    break;
            }
        }
        else {
            switch (token) {
                case '[':
                    acc.path.push('list');
                    acc.tree = acc.tree.setIn(acc.path, immutable_1.Map({}));
                    break;
                case '*':
                    acc.path.push('computed');
                    acc.tree = acc.tree.setIn(acc.path, immutable_1.Map({}));
                    break;
                case '{':
                    acc.path.push('record');
                    acc.tree = acc.tree.setIn(acc.path, immutable_1.Map({}));
                    acc.mode = ParserMode.RecordKey;
                    break;
                case ':':
                    acc.mode = ParserMode.Basic;
                    acc.tree = acc.tree.setIn(acc.path, immutable_1.Map({}));
                    break;
                case ',':
                    while (acc.path.length > 0 && acc.path[acc.path.length - 1] != 'record') {
                        acc.path.pop();
                    }
                    acc.mode = ParserMode.RecordKey;
                    break;
            }
        }
        return acc;
    }, { tree: immutable_1.Map(), mode: ParserMode.Basic, path: [] }, tokens);
    return parser.tree;
}
exports.fromTypeString = fromTypeString;
//# sourceMappingURL=type.js.map